{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1. OpenCV 套件\n",
    "### 概要 :\n",
    "> * OpenCV 全名是 Open Source Computer Vision ( Library )\n",
    "> * 白 / 黑盒子 : 介面, 參數, 傳回值\n",
    "> * 演算法 : 需了解基本原理, 對運用極有幫助, 非探究數學推倒\n",
    "> * 應  用 : 需掌握正確使用方法\n",
    "> * Q&A 社團 iCoding : https://www.facebook.com/groups/216955676502460\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-1: OpenCV 環境安裝\n",
    "### `NOT suggest to use Conda or VS code`\n",
    "> * 在 (命令提示字元 / Windows PowerShel `系統管理員`) 身分下打 pip install jupyterlab 指令( `灌程式` )\n",
    "> * 在 (命令提示字元 / Windows PowerShell `一般身分`)下打 jupyter lab ( `執行程式` )(shell> jupyter lab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anaconda : 建立 python 3.6.x 虛擬環境\n",
    "> * or install Anaconda ( :>jupyter notebook) (暫不建議, 為了維持一套 python 在電腦中)\n",
    "> * conda create --name py36x python=3.6.8 --channel conda-forge<br>\n",
    "> * 回到 conda Home 將 JupyterLab install & Launch<br>\n",
    "> [`conda install -c conda-forge jupyterlab`]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### install following in command line :\n",
    "> * install python `3.6.X`\n",
    "> * `pip install jupyterlab ( 上面 conda install -c conda-forge jupyterlab 已經跑過，就不要再跑了 )`\n",
    "---\n",
    "> * pip install opencv-python\n",
    "> * pip install opencv-contrib-python\n",
    "> * pip install matplotlib\n",
    "> * pip install scikit-image\n",
    "> * pip install imutils\n",
    "> * pip install dlib==`19.8.1` <br>\n",
    "> ( or dlib-19.8.1-cp36-cp36m-win_amd64.whl ) x`python 3.6.x`)\n",
    "> * pip install pytesseract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jupyter 快捷鍵\n",
    "> * shift-enter : 跑程式\n",
    "> * A : 上面增加一格\n",
    "> * B : 下面增加一格\n",
    "> * C : 複製 (crtl + C)\n",
    "> * V : 貼上 (crtl + V)\n",
    "> * Z : 復原 (crtl + Z)\n",
    "> * X : 剪下 (crtl + X)\n",
    "> * shift-up & shift-down: 多個 block 選取\n",
    "> * M : markdown 抄筆記\n",
    "> * shift + tab : param instruction\n",
    "> * tab : functions instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import dlib\n",
    "import sys\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "print(f'python ver.\\t: {sys.version}\\n'\n",
    "      f'cv2 ver.\\t: {cv2.__version__}\\n'\n",
    "      f'numpy ver.\\t: {np.__version__}\\n'\n",
    "      f'matplotlib ver.\\t: {matplotlib.__version__}\\n'\n",
    "      f'dlib ver.\\t: {dlib.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-2: 彩色、灰階照片讀取 / 寫入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read / Open image file : `B:0, G:1, R:2`\n",
    "><img src=\".\\image\\rgb01.png\"  style='height:250px; width:520px'>\n",
    "><img src=\".\\image\\image2vector.png\"  style='height:250px; width:520px'>\n",
    "\n",
    "> 讀取支援的格式：bmp, pbm, pgm, ppm, jpeg, jpg, tiff, tif, png ....<br>\n",
    "> https://docs.opencv.org/master/d4/da8/group__imgcodecs.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RGB to Gray ?\n",
    "* 加權平均法 : 根據重要性及其它指標，將三個分量以不同的權值進行加權平均。由於人眼對綠色的敏感最高，對藍色敏感最低，因此，按下式對RGB三分量進行加權平均能得到較合理的灰度影像。\n",
    "> $F(i, j) = 0.299 R(i, j) + 0.587 G(i, j) + 0.114 B(i, j)$\n",
    "\n",
    "* 分量法 : 將彩色影像中的三分量的亮度作為三個灰度影像的灰度值，可根據應用需要選取一種灰度影像。\n",
    "> $F1(i, j) = R(i, j)$<br>\n",
    "> $F2(i, j) = G(i, j)$<br>\n",
    "> $F3(i, j) = B(i, j)$\n",
    "\n",
    "* 最大值法 : 將彩色影像中的三分量亮度的最大值作為灰度圖的灰度值。\n",
    "> $F(i, j) = max(R(i, j), G(i, j), B(i, j))$\n",
    "\n",
    "* 平均值法 : 將彩色影像中的三分量亮度求平均得到一個灰度值。\n",
    "> $F(i, j) = \\frac{(R(i, j) + G(i, j) + B(i, j))}{3}$\n",
    "\n",
    "### Gray to RGB : $R ← Gray, G ← Gray, B ← Gray$<br>\n",
    "https://docs.opencv.org/3.4/de/d25/imgproc_color_conversions.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read image file \n",
    "| 數值 |      含意      |           語法         |\n",
    "|:----:|:-------------:|:--------------------:|\n",
    "|  -1  | 保持原格式不便 | cv2.IMREAD_UNCHANGED |\n",
    "|  0   |  單通道灰階    | cv2.IMREAD_GRAYSCALE | \n",
    "|  1   | 3通道BGR (`預設`) |   cv2.IMREAD_COLOR   | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imshow\n",
    "* 如果圖像是 8 位無符號，則按原樣顯示。\n",
    "* 如果圖像是 16 位無符號或 32 位整數，則將像素除以 256。即值範圍 [0, 255*256] 映射到 [0, 255]。\n",
    "* 如果圖像是 32 位或 64 位浮點，則像素值乘以 255。即值範圍 [0, 1] 映射到 [0, 255]。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img0 = cv2.imread('./image/SpongeBob.jpg', cv2.IMREAD_GRAYSCALE)  # same\n",
    "# img0 = cv2.imread('./image/SpongeBob.jpg', 0)    # 0 灰階\n",
    "\n",
    "img1 = cv2.imread('./image/SpongeBob.jpg', cv2.IMREAD_COLOR)    # 1 BGR,  1 可省略(原圖)\n",
    "# img1 = cv2.imread('./image/SpongeBob.jpg', 1)                 # 1 BGR,  1 可省略(原圖)\n",
    "\n",
    "cv2.imshow('SpongeBob Gray uint8', img0)\n",
    "# cv2.waitKey(0)\n",
    "cv2.imshow('SpongBob Color uint8', img1)             # unit8\n",
    "cv2.imshow('SpongBob Color *256', img1*256)          # unit16\n",
    "cv2.imshow('SpongBob Color 1/255 float', img1/255)   # floating 0.0 ~ 1.0\n",
    "\n",
    "cv2.waitKey(0)                                       # 0 wait for anykey任意按鍵, try 3000\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### image from numpy point of view\n",
    "\n",
    "#### Data Types for ndarrays\n",
    "\n",
    "|名稱          |描述                                              |簡寫|\n",
    "|--------------|-------------------------------------------------|----|\n",
    "|np.bool\t   |用一個位元組儲存的布爾型別（True或False）           |'b' |\n",
    "|np.int8\t   |一個位元組大小，-128 至 127\t                      |'i' |\n",
    "|np.int16\t   |整數，-32768 至 32767\t                          |'i2'|\n",
    "|np.int32\t   |整數，-2^31​ 至 2^32 -1\t                          |'i4'|\n",
    "|np.int64\t   |整數，-2^63 至 2^63 - 1\t                          |'i8'|\n",
    "|`np.uint8`\t   |`無符號整數，0 至 255`\t                            |'u'|\n",
    "|np.uint16\t   |無符號整數，0 至 65535\t                            |'u2'|\n",
    "|np.uint32\t   |無符號整數，0 至 2^32 - 1\t                        |'u4'|\n",
    "|np.uint64\t   |無符號整數，0 至 2^64 - 1\t                        |'u8'|\n",
    "|np.float16\t   |半精度浮點數：16位元，正負號1位，指數5位，精度10位    |'f2'|\n",
    "|np.float32    |單精度浮點數：32位元，正負號1位，指數8位元，精度23位  |'f4'|\n",
    "|np.float64    |雙精度浮點數：64位元，正負號1位，指數11位，精度52位   |'f8'|\n",
    "|np.complex64  |複數，分別用兩個32位元浮點數表示實部和虛部            |'c8'|\n",
    "|np.complex128 |複數，分別用兩個64位元浮點數表示實部和虛部            |'c16'|\n",
    "|np.object_\t   |python物件\t                                     |'O' |\n",
    "|np.string_\t   |字串\t                                             |'S' |\n",
    "|np.unicode_   |unicode型別                                        |'U' |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 灰階\n",
    "print(f'gray\\t:\\nshape\\t: {img0.shape}\\n'\n",
    "      f'ndim\\t: {img0.ndim}\\n'\n",
    "      f'size\\t: {img0.size}\\n'\n",
    "      f'dtype\\t: {img0.dtype}\\n'\n",
    "      f'type\\t: {type(img0)}\\n{\"=\"*40}')\n",
    "\n",
    "# 1 RGB\n",
    "print(f'color\\t:\\nshape\\t: {img1.shape}\\n'\n",
    "      f'ndim\\t: {img1.ndim}\\n'\n",
    "      f'size\\t: {img1.size}\\n'\n",
    "      f'dtype\\t: {img1.dtype}\\n'\n",
    "      f'type\\t: {type(img1)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### img one pixel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img0[0,0])  # gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img1[0,0])  # color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### matplotlib show RGB (matplt) vs. BGR (cv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img_bgr = cv2.imread('./image/baby.jpg', 1)      # 使用 OpenCV 讀取圖檔\n",
    "\n",
    "img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)    # 將 BGR 圖片轉為 RGB 圖片\n",
    "# img_rgb = img_bgr[:,:,::-1]                         # 或是這樣亦可\n",
    "\n",
    "plt.figure(figsize=(16, 9))                # 使用 Matplotlib 顯示圖片\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img_rgb)\n",
    "plt.title('rgb')\n",
    "\n",
    "plt.subplot(122), plt.imshow(img_bgr), plt.title('bgr')\n",
    "plt.imshow\n",
    "\n",
    "cv2.imshow('bgr', img_bgr)                     # cv2 show bgr\n",
    "cv2.waitKey(0)                                 # 0 wait for anykey任意按鍵, try 3000\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write / Save image file : imwrite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img0 = cv2.imread('./image/baby.jpg', 0)    # 0 灰階\n",
    "cv2.imwrite('./image/baby01.jpg', img0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-3: OpenCV 影像基礎操作\n",
    "><img src=\".\\image\\array_3d.jpg\"  style='height:300px; width:600px'>\n",
    "><img src=\".\\image\\MagicBox.jpg\"  style='height:300px; width:400px'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "\n",
    "img = cv2.imread('./image/lenaColor.png')    #調用cv2.imread()讀取影像\n",
    "\n",
    "if img is None:\n",
    "\tsys.exit('無法讀取影像...')\n",
    "else :\n",
    "    print(f'img size : {img.shape}')\n",
    "    cv2.imshow('Image Show', img)           #調用cv2.imshow() 顯示讀取進來的影像\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() \n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#指定pix位置 x, y\n",
    "a=100\n",
    "px = img[a, a]             # RGB 100, 100 的值\n",
    "print(px)                  #顯示BGR顏色數值\n",
    "\n",
    "blue = img[a, a, 0]        # 0:Blue, 1:Green, 2:Red 指定 x, y座標上 0 通道到數值\n",
    "print(blue)\n",
    "\n",
    "img[a, a] = [0, 0, 0]      # 指定圖片像素值[B, G, R] 給 0 值\n",
    "print(img[a, a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基於numpy的資料格式指定物件\n",
    "img = cv2.imread('./image/lenaColor.png')    #調用cv2.imread()讀取影像\n",
    "\n",
    "print(f'(10, 10, 2)像素的紅色數值\\t: {img.item(10, 10, 2)}\\n'    # 0:Blue, 1:Green, 2:Red\n",
    "      f'(10, 10, 2)像素的紅色數值\\t: {img[10, 10, 2]}\\n')        # 0:Blue, 1:Green, 2:Red\n",
    "\n",
    "#修改像素值 itemset\n",
    "img.itemset((10, 10, 2), 120) # set (10, 10, 2) = 120\n",
    "img[10, 10, 2] = 120          # set (10, 10, 2) = 120\n",
    "\n",
    "print(f'after itemset\\t\\t\\t: {img.item(10, 10, 2)}\\n' # 120\n",
    "      f'after img[10,10,2]\\t\\t: {img[10, 10, 2]} \\n')  # 120\n",
    "\n",
    "print(f'img.shape\\t\\t\\t: {img.shape}\\n'  #行、列、通道;圖像長寬與通道數(channels),可以判斷灰階或彩圖\n",
    "      f'img.size\\t\\t\\t: {img.size:,}\\n'   #像素總量 w*h*c\n",
    "      f'img.dtype\\t\\t\\t: {img.dtype}')  #像素資料型態 uint8(0~255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corp_image - ROI ( Region of Interest )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#分割圖像區域\n",
    "logo = img[100:400, 150:415]    # x1, x2, : y1, y2\n",
    "print(f'logo size : {logo.shape}')\n",
    "\n",
    "cv2.imshow('Image Show', logo)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('./image/assassin.jpg')\n",
    "cropped = img[100:400, 200:500] \n",
    "\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('assassin face', cropped)\n",
    "print(f'cropped size : {cropped.shape}')\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分割與合併，色彩通道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('./image/assassin.jpg')\n",
    "\n",
    "b, g, r = cv2.split(img)     #分割通道\n",
    "\t\n",
    "# b = img[:,:,0];  g = img[:,:,1];  r = img[:,:,2]  #也可以陣列指定通道分割\n",
    "print(f'{b.shape}\\n\\n'\n",
    "      f'r =\\n{r}')\n",
    "\n",
    "cv2.imshow('b', b)\n",
    "cv2.imshow('g', g)\n",
    "cv2.imshow('r', r)\n",
    "\n",
    "cv2.imshow('rgb', cv2.merge([r,g,b]))\n",
    "cv2.imshow('bgr', cv2.merge([b,g,r]))\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### image 3D data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import cv2\n",
    "\n",
    "# from matplotlib import cm\n",
    "\n",
    "img1 = cv2.imread('./image/contour.png', 0)  # queryImage\n",
    "# img1 = cv2.imread('./image/blackhat.bmp', 0)  # queryImage\n",
    "# img1 = cv2.imread('./image/contour.png', 0)  # queryImage\n",
    "\n",
    "w, h = img1.shape\n",
    "X = np.arange(0, h, 1)\n",
    "Y = np.arange(0, w, 1)\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "# Z=img1\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = Axes3D(fig)\n",
    "# ax.view_init(30, 0)\n",
    "surf = ax.plot_surface(X, Y, img1, rstride=1, cstride=1 , cmap=plt.get_cmap('rainbow'))\n",
    "\n",
    "fig.colorbar(surf, shrink=.6, aspect=10)\n",
    "\n",
    "ax.contourf(X, Y, img1, zdir='z', offset=-2, cmap=plt.get_cmap('rainbow'))\n",
    "ax.set_zlim(0, 255)\n",
    "ax.set_xlabel('w :'+str(h));   ax.set_ylabel('h :'+str(w));   ax.set_zlabel('gray value :255');\n",
    "plt.show()\n",
    "\n",
    "cv2.imshow('bgr', cv2.imread('./image/contour.png', 1))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 2. OpenCV 繪圖\n",
    "\n",
    "## 2-1: 基礎繪圖\n",
    "> OpenCV 在圖片上加上線條等幾何圖案以及文字標示。在影像處理的程式中，若要比較清楚呈現處理的結果，時常會需要在圖片上加上一些標示的幾何圖形或是文字，比方說在物件辨識的問題上，可能會使用方框將辨識出來的物件框起來，並加註一些文字描述等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### line : cv2.line ( 影像, 開始座標, 結束座標, 顏色, 線條寬度 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "gc = np.zeros((512, 512, 3), dtype='uint8')\n",
    "\n",
    "cv2.line(gc, (10, 50), (400, 300), (255, 0, 0), 5)\n",
    "cv2.line(gc, (100, 50), (400, 500), (0, 0, 255), 3)\n",
    "cv2.imshow('draw', gc) \n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rectangle : cv2.rectangle(影像, 頂點座標, 對向頂點座標, 顏色, 線條寬度)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc = np.zeros((512, 512, 3), dtype='uint8')\n",
    "\n",
    "cv2.rectangle(gc, (30, 50), (200, 280), (0, 0, 255), 5)\n",
    "cv2.rectangle(gc, (100, 200), (296, 376), (234, 151, 102), -1)   # -1 : 實心框\n",
    "cv2.imshow('draw', gc) \n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### circle : cv2.circle ( 影像, 圓心座標, 半徑, 顏色, 線條寬度 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc = np.zeros((512, 512, 3), dtype='uint8')\n",
    "\n",
    "cv2.circle(gc, (200, 100), 80, (255, 255, 0), -2)\n",
    "cv2.circle(gc, (280, 180), 60, (147, 147, 147), 3)\n",
    "cv2.imshow('draw', gc) \n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ellipse : cv2.ellipse ( 影像, 中心座標, (長軸, 短軸), 旋轉角度, 起始角度, 結束角度, 顏色, 線條寬度 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc = np.zeros((512, 512, 3), dtype='uint8')\n",
    "\n",
    "cv2.ellipse(gc, (200, 100), (80, 40), 45, 0, 360, (80, 127, 255), 5)\n",
    "cv2.ellipse(gc, (250, 300), (90, 50), 0, 0, 270, (44, 141, 108), -1)\n",
    "cv2.imshow('draw', gc) \n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cv2.polylines ( 影像, 頂點座標, 封閉型, 顏色, 線條寬度 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc = np.zeros((512, 512, 3), dtype='uint8')\n",
    "\n",
    "#設定頂點座標\n",
    "pts = np.array(((100,50), (100,200), (170,300), (300,50)))\n",
    "\n",
    "cv2.polylines(gc, [pts], 1, (105, 105, 255), 2)  #True:頭尾相連; False:頭尾不相連\n",
    "cv2.imshow('draw', gc) \n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Operation ( +, add )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img1 = np.random.randint(0, 256, size=[3,3], dtype=np.uint8)\n",
    "img2 = np.random.randint(0, 256, size=[3,3], dtype=np.uint8)\n",
    "\n",
    "print(f'img1 :\\n{img1}\\n\\n'\n",
    "      f'img2 :\\n{img2}\\n\\n'\n",
    "      f'img1+img2 :\\n{img1+img2}\\n\\n'           # still np.uint8, sign problem\n",
    "      f'cv2.add(img1,img2) :\\n{cv2.add(img1, img2)}')  # 255 飽和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img1=cv2.imread('./image/cat.jpg')\n",
    "img2=img1.copy()\n",
    "\n",
    "cv2.imshow('img1 + img2', img1+img2)\n",
    "cv2.imshow('cv2.add(img1, img2)', cv2.add(img1,img2))\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(121)\n",
    "plt.imshow(cv2.cvtColor(img1+img2, cv2.COLOR_BGR2RGB))   # same as img*2\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(cv2.cvtColor(cv2.add(img1, img2), cv2.COLOR_BGR2RGB))  # same as add(img1, img2)\n",
    "plt.show()\n",
    "\n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### img + 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img1=cv2.imread('./image/cat.jpg', 1)\n",
    "\n",
    "cv2.imshow('img1', img1)\n",
    "cv2.imshow('img1+50', cv2.add(img1, 50))\n",
    "\n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Operation ( ADD Weighted )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img1=cv2.imread('./image/cat.jpg', 1)\n",
    "img2=cv2.imread('./image/lenaColor.png', 1)\n",
    "\n",
    "img1 = cv2.resize(img1, (450, 450))\n",
    "img2 = cv2.resize(img2, (450, 450))\n",
    "\n",
    "result = cv2.addWeighted(img1, 0.8, img2, 0.2, 0)  # img1*0.4 + img2*0.6 + 0\n",
    "\n",
    "cv2.imshow('weighted image', result)\n",
    "\n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bitwise : and, or, xor, not\n",
    "><img src=\".\\image\\truth-table.png\"  style='height:250px; width:750px'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "rectangle = np.zeros((300, 300), dtype = 'uint8')          # zero 黑色畫布\n",
    "cv2.rectangle(rectangle, (25, 25), (275, 275), 255, -1)   # Draw filled rectangle\n",
    "cv2.imshow('Rectangle', rectangle)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "circle = np.zeros((300, 300), dtype = 'uint8')\n",
    "cv2.circle(circle, (150, 150), 150, 255, -1)              # Draw filled circle\n",
    "cv2.imshow('Circle', circle)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "bitwiseAnd = cv2.bitwise_and(rectangle, circle)           # and expression\n",
    "cv2.imshow('AND', bitwiseAnd)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "bitwiseOr = cv2.bitwise_or(rectangle, circle)             # or expression\n",
    "cv2.imshow('OR', bitwiseOr)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "bitwiseXor = cv2.bitwise_xor(rectangle, circle)          # xor expression\n",
    "cv2.imshow('XOR', bitwiseXor)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "bitwiseNot = cv2.bitwise_not(circle)                     # not expression\n",
    "cv2.imshow('NOT', bitwiseNot)\n",
    "\n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### font\n",
    "><img src=\".\\image\\font.jpg\"  style='height:250px; width:520px'>\n",
    "### cv2.putText(影像, 文字, 座標, 字型, 大小, 顏色, 線條寬度, 線條種類)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "#建立 512x512 的白色畫布\n",
    "gc = np.full((512, 1180, 3), 255, dtype='uint8')  # 用(B, G, R) = (255, 255, 255): 白色填滿畫布\n",
    "\n",
    "font = [cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        cv2.FONT_HERSHEY_PLAIN,\n",
    "        cv2.FONT_HERSHEY_DUPLEX,\n",
    "        cv2.FONT_HERSHEY_COMPLEX,\n",
    "        cv2.FONT_HERSHEY_TRIPLEX,\n",
    "        cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
    "        cv2.FONT_HERSHEY_SCRIPT_SIMPLEX,\n",
    "        cv2.FONT_HERSHEY_SCRIPT_COMPLEX ]\n",
    "\n",
    "for idx, f in enumerate(font):\n",
    "    cv2.putText(gc, 'OpenCV_AA', (20, 60*(idx+1)), f, 2, (0,0,0), 2, cv2.LINE_AA)  # FILLED\n",
    "    cv2.putText(gc, 'OpenCV_8', (440, 60*(idx+1)), f, 2, (0,0,0), 2, cv2.LINE_8)\n",
    "    cv2.putText(gc, 'OpenCV_4', (820, 60*(idx+1)), f, 2, (0,0,0), 2, cv2.LINE_4)\n",
    "\n",
    "cv2.imshow('draw', gc)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 練習 2-1\n",
    "在一個 $512*512*3$ 的黑色畫布上, 利用畫圓的函數 cv2.circle, for loop 和 亂數\n",
    ">* 畫出 12 等距同心圓\n",
    ">* 12 同心圓RGB顏色隨機變換, 每次不一樣<br>\n",
    "><img src=\".\\image\\circle2-1.jpg\"  style='height:300px; width:300px'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "gc = np.zeros((512, 512, 3), dtype='uint8')\n",
    "\n",
    "# -------- code start -------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --------- code end --------------------\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 練習 2-2\n",
    "在一個 $512*512*3$ 的黑色畫布上, 利用畫圓的函數 cv2.ellipse 和 for loop\n",
    ">* 畫出 12 或 更多 同心等分 360 度橢圓, 顏色一樣<br>\n",
    "><img src=\".\\image\\ellipse2-2.jpg\"  style='height:300px; width:300px'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc = np.zeros((512, 512, 3), dtype='uint8')\n",
    "\n",
    "unit = 50\n",
    "# -------- code start ------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -------- code end --------------------\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-2: 滑鼠交互\n",
    "### onmouse(event, x, y, flags, param)\n",
    "\n",
    "> 事件代號 (int event), 座標 (int x,int y), 旗標代號 (int flag), 滑鼠事件的代號名稱 (param)\n",
    "> * event : 代表的是滑鼠回傳的事件號碼，每當滑鼠有動作，event就會回傳訊息到 onMouse()，也順便回傳滑鼠移動的座標\n",
    "> * flag : 代表的是拖曳事件\n",
    "> * param : 則是自己定義 onMouse() 事件的ID，就跟 GUI 介面的視窗介面 ID 一樣 (cvGetWindowHandle())，不過這邊是自己給的編號，而視窗介面的 ID 則是系統自動隨機分配的 ID，而滑鼠事件的執行可以細分為：\n",
    "\n",
    ">>### event :\n",
    "|      事件 event       | 值 |  動作   |\n",
    "|:---------------------:|:-:|:-------:|\n",
    "|CV_EVENT_MOUSEMOVE     | 0 |   滑動   |\n",
    "|CV_EVENT_LBUTTONDOWN   | 1 | 左鍵點擊 |\n",
    "|CV_EVENT_RBUTTONDOWN   | 2 | 右鍵點擊 |\n",
    "|CV_EVENT_MBUTTONDOWN   | 3 | 中鍵點擊 |\n",
    "|CV_EVENT_LBUTTONUP     | 4 | 左鍵放開 |\n",
    "|CV_EVENT_RBUTTONUP     | 5 | 右鍵放開 |\n",
    "|CV_EVENT_MBUTTONUP     | 6 | 中鍵放開 |\n",
    "|CV_EVENT_LBUTTONDBLCLK | 7 | 左鍵雙擊 |\n",
    "|CV_EVENT_RBUTTONDBLCLK | 8 | 右鍵雙擊 |\n",
    "|CV_EVENT_MBUTTONDBLCLK | 9 | 中鍵雙擊 |\n",
    "\n",
    ">>### Flag : \n",
    "|       旗標 flag       | 值 |  動作   |\n",
    "|:---------------------:|:--:|:---------------------:|\n",
    "|CV_EVENT_FLAG_LBUTTON  | 1  |  左鍵拖曳              |\n",
    "CV_EVENT_FLAG_RBUTTON   | 2  |  右鍵拖曳              |\n",
    "CV_EVENT_FLAG_MBUTTON   | 4  |  中鍵拖曳              |\n",
    "CV_EVENT_FLAG_CTRLKEY   | 8  | (8~15)按Ctrl不放事件   |\n",
    "CV_EVENT_FLAG_SHIFTKEY  | 16 | (16~31)按Shift不放事件 |\n",
    "CV_EVENT_FLAG_ALTKEY    | 32 | (32~39)按Alt不放事件   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def onmouse(event, x, y, flags, param):   #標準滑鼠互動函式\n",
    "    if event == 1:                          #當滑鼠移動時\n",
    "        print(f'BGR : {img[y, x]}, x:{x}, y:{y},', end='     ')  #顯示滑鼠所在畫素的數值，注意畫素表示方法和座標位置的不同\n",
    "#========= main =====================\n",
    "img= cv2.imread('./image/mybaby.jpg')       #定義圖片位置\n",
    "\n",
    "cv2.namedWindow('img')                     #構建視窗\n",
    "cv2.setMouseCallback('img', onmouse)       #回撥繫結視窗\n",
    "\n",
    "while True:                                #無限迴圈\n",
    "    cv2.imshow('img', img)\n",
    "    if cv2.waitKey() == 27:               #按下‘ESC'鍵，退出\n",
    "        break                      \n",
    "\n",
    "cv2.destroyAllWindows()                    #關閉視窗\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 長方形拖曳"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "drawing = False\n",
    "ix, iy = -1, -1\n",
    "\n",
    "def draw_rect(event, x, y, flags, param):\n",
    "    global ix, iy, drawing, mode\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        drawing = True\n",
    "        ix, iy = x, y\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if drawing == True:\n",
    "            cv2.rectangle(img, (ix,iy), (x,y), (0,255,0), 1)\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        drawing = False\n",
    "        cv2.rectangle(img, (ix,iy), (x,y), (0,255,0), 1)\n",
    "\n",
    "img = np.zeros((512, 512, 3), np.uint8)\n",
    "cv2.namedWindow('image')\n",
    "cv2.setMouseCallback('image', draw_rect)\n",
    "\n",
    "while True:\n",
    "    cv2.imshow('image', img)\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-3: 滾動條"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "img = np.zeros((512, 512, 3), np.uint8)  # empty image\n",
    "cv2.namedWindow('Track Bar')\n",
    "\n",
    "# creat track bars\n",
    "cv2.createTrackbar('R', 'Track Bar', 0, 255, nothing)   # in 'Track Bar' windows\n",
    "cv2.createTrackbar('G', 'Track Bar', 0, 255, nothing)\n",
    "cv2.createTrackbar('B', 'Track Bar', 0, 255, nothing)\n",
    "cv2.createTrackbar('1:ON\\n0:OFF', 'Track Bar', 0, 1, nothing)  # need nothing to call function\n",
    "\n",
    "while True :\n",
    "    R = cv2.getTrackbarPos('R', 'Track Bar')\n",
    "    G = cv2.getTrackbarPos('G', 'Track Bar')\n",
    "    B = cv2.getTrackbarPos('B', 'Track Bar')\n",
    "    F = cv2.getTrackbarPos('1:ON\\n0:OFF', 'Track Bar')\n",
    "\n",
    "    if F == 1:\n",
    "        img[:]=[B, G, R]\n",
    "    else:\n",
    "        img[:]=[0,0,0]\n",
    "        \n",
    "    cv2.imshow('Track Bar', img)\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### example HSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "pic = cv2.imread('./image/lenaColor.png')\n",
    "pic = cv2.cvtColor(pic, cv2.COLOR_BGR2HSV)  # 將 BGR圖像轉化為 HSV 圖像\n",
    "\n",
    "# 顯示原圖像做對比\n",
    "# cv2.namedWindow('old', cv2.WINDOW_NORMAL) \n",
    "cv2.imshow('old', pic) \n",
    "\n",
    "# 新圖像窗口\n",
    "# cv2.namedWindow('new', cv2.WINDOW_AUTOSIZE) \n",
    "cv2.imshow('new', pic) \n",
    "\n",
    "#初始化滾動條\n",
    "cv2.createTrackbar('H', 'new', 10, 15, nothing)\n",
    "cv2.createTrackbar('S', 'new', 10, 15, nothing)\n",
    "cv2.createTrackbar('V', 'new', 10, 15, nothing)\n",
    "\n",
    "while True:\n",
    "\t# ESC按下退出\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        print('finish !!!')\n",
    "        break\n",
    "\t# 讀取滚動條現在的滾動條的 HSV 信息\n",
    "    h_value = float(cv2.getTrackbarPos('H', 'new')/10)  # 1 ~ 1.5\n",
    "    s_value = float(cv2.getTrackbarPos('S', 'new')/10)  # 1 ~ 1.5\n",
    "    v_value = float(cv2.getTrackbarPos('V', 'new')/10)  # 1 ~ 1.5\n",
    "\t# 拆分、讀入新數據後，重新合成調整後的圖片\n",
    "    H, S, V = cv2.split(pic)\n",
    "    new_pic = cv2.merge([np.uint8(H*h_value) , np.uint8(S*s_value) , np.uint8(V*v_value)])\n",
    "    cv2.imshow('new', new_pic)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3. 色彩空間\n",
    "> 色彩空間是描述使用一組值（通常使用三個、四個值或者顏色成分）表示顏色方法的抽像數學模型，也被稱作「色域」。\n",
    "\n",
    "> 通常使用`RGB（紅色、綠色、藍色）`色彩空間定義，這是另外一種生成同樣顏色的方法，紅色、綠色、藍色被當作X、Y和Z坐標軸。另外一個生成同樣顏色的方法是使用`色相（X軸）、飽和度（色度）（Y軸）和明度（Z軸）`表示，這種方法稱為HSV色彩空間。另外還有許多其它的色彩空間，許多可以按照這種方法用三維（X、Y、Z）、更多或者更少維表示，但是有些根本不能用這種方法表示。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-1: RGB\n",
    "> RGB色彩空間是RGB色彩空間之一，以單色（單一波長）原色的特定集合著稱\n",
    "\n",
    "> 最常用的是 24 位實現方法，也就是紅綠藍每個通道有 8 位元或者 256 色級。基於這樣的 24 位 RGB 模型的色彩空間可以表現 `256 × 256 × 256 ≈ 1677` 萬色。一些實現方法採用每原色 16 位元，能在相同範圍內實現更高更精確的色彩密度。這在寬域色彩空間中尤其重要，因為大部分通常使用的顏色排列的相對更緊密。\n",
    "\n",
    "> 為什麼 RGB 不夠好 !!!\n",
    "\n",
    "> 任何的色彩都可由紅、綠、及藍三原色光混合而成，而 CRT、LCD 顯示及電漿螢幕等，確實都透過套用不同的紅、綠、及藍色次像素（Sub-Pixel）陣列的密度，而產生彩色影像。但事實上，有許多色彩卻是沒辦法以這樣的方法產生。尤其是，沒辦法產生各式各樣的青綠色（Blue-Green)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "image = cv2.imread('./image/assassin.jpg')\n",
    "cv2.imshow('Original', image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n",
    "image[:2]  # 3D BGR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BGR to RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "# img=np.random.randint(0,256,size=[2,4,3],dtype=np.uint8)\n",
    "img = cv2.imread('./image/assassin.jpg')\n",
    "\n",
    "rgb=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "bgr=cv2.cvtColor(rgb, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('rgb', rgb)\n",
    "cv2.imshow('bgr', bgr)\n",
    "\n",
    "print(f'img=\\n{img[:2]}\\n\\n'\n",
    "      f'rgb=\\n{rgb[:2]}\\n\\n'\n",
    "      f'bgr=\\n{bgr[:2]}')\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-2: Gray\n",
    "> 基礎 : 對於彩色轉灰度，有一個很著名的心理學公式：\n",
    "\n",
    ">> $Gray = R * 0.299 + G * 0.587 + B * 0.114$\n",
    "\n",
    "> 整數算法\n",
    "\n",
    "> * 而實際應用時，希望避免低速的浮點運算，所以需要整數算法。注意到係數都是 3 位精度，我們可以將它們縮放 1000 倍來實現整數運算算法：\n",
    "\n",
    ">> $ Gray = (R * 299 + G * 587 + B * 114 + 500)$ / $1000 $\n",
    "\n",
    "> * RGB 一般是 8 位精度，現在縮放 1000 倍，所以上面的運算是 32 位整型的運算。注意後面那個除法是整數除法，所以需要加上 500 來實現四捨五入。就是由於該算法需要 32 位運算，所以該公式的另一個變種很流行：\n",
    "\n",
    ">> $Gray = (R * 30 + G * 59 + B * 11 + 50)$ / $100$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BGR to Gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 206 types of cvtColor\n",
    "# Gray\n",
    "image = cv2.imread('./image/assassin.jpg')\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('Gray', gray)\n",
    "\n",
    "print(f'image :\\n{image[:2]}\\n\\n'\n",
    "      f'gray :\\n{gray[:2]}')   # row 0 ~ 1, 全部 column \n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gray to BGR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "# img = cv2.imread('./image/lady_gray.png')      # error \n",
    "img = cv2.imread('./image/lenaGray.bmp', 0)     # 2d\n",
    "\n",
    "rst=cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)       # BGR color 3d\n",
    "img[:2], rst[:2]   # row 0 ~ 1, 全部 column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-3: HSV\n",
    " * HSV / HSL 即`色相、飽和度、明度 / 亮度`（英語：Hue, Saturation, Value / Lightness），又稱 HSB，其中B即英語：Brightness。另外一個生成同樣顏色的方法是使用 : 色相（X軸）、飽和度（色度）（Y軸）和明度（Z軸）表示，這種方法稱為 HSV 色彩空間\n",
    "\n",
    "> * 色調(Hue) : 色彩的顏色名稱，如紅色、黃色等<br>\n",
    "> 在HSL中，色調 (Hue) 決定了的顏色， 用 `360 度`來劃分，就像傳統的色輪。 HSL相對於 RGB 顏色的主要優勢之一是互補色彼此相對, 這使得整個`系統非常直觀`。用角度度量，取值範圍為0°～360°，從紅色開始按逆時針方向計算，`紅色為0°，綠色為120°，藍色為240°`。它們的補色分別是：黃色為60°，青色為180°，洋紅色300°\n",
    "\n",
    "> * 飽和度 (Saturation) : 色彩的純度，越高色彩越純，低則逐漸變灰，數值為 0-100%<br>\n",
    "> 與色輪中心的距離稱為 \"飽和度\" 。 仔細觀察上面的色輪，距離圓心越遠，顏色更明亮，更鮮豔。\n",
    "\n",
    "> * 明度（Value），亮度 (Lightness) : 數值為 0-100%。\n",
    "\n",
    ">><img src=\".\\image\\hsl-hsv.png\"  style='height:400px; width:520px'>\n",
    "https://www.itread01.com/content/1549111148.html\n",
    "\n",
    "https://zh.wikipedia.org/zh-tw/HSL%E5%92%8CHSV%E8%89%B2%E5%BD%A9%E7%A9%BA%E9%97%B4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HSV 色調 (Hue) : 0 ~ 360, \n",
    "### OpenCV <br>\n",
    "> * ### `Hue : [0, 179]`<br>\n",
    "> * ### Saturation : [0, 255]<br>\n",
    "> * ### Value : [0, 255]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#=========test blue in HSV=============\n",
    "imgBlue=np.zeros([1,1,3],dtype=np.uint8)\n",
    "imgBlue[0,0,0]=255\n",
    "BlueHSV=cv2.cvtColor(imgBlue,cv2.COLOR_BGR2HSV)\n",
    "print(f'Blue\\t\\t= {imgBlue}\\n'\n",
    "      f'BlueHSV\\t\\t= {BlueHSV}\\n')\n",
    "\n",
    "#=========test green in HSV=============\n",
    "imgGreen=np.zeros([1,1,3],dtype=np.uint8)\n",
    "imgGreen[0,0,1]=255\n",
    "GreenHSV=cv2.cvtColor(imgGreen,cv2.COLOR_BGR2HSV)\n",
    "print(f'Green\\t\\t= {imgGreen}\\n'\n",
    "      f'GreenHSV\\t= {GreenHSV}\\n')\n",
    "\n",
    "#=========test red in HSV=============\n",
    "imgRed=np.zeros([1,1,3],dtype=np.uint8)\n",
    "imgRed[0,0,2]=255\n",
    "RedHSV=cv2.cvtColor(imgRed,cv2.COLOR_BGR2HSV)\n",
    "print(f'Red\\t\\t= {imgRed}\\n'\n",
    "      f'RedHSV\\t\\t= {RedHSV}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XYZ :\n",
    "><img src=\".\\image\\rgb2xyz.jpg\"  style='height:250px; width:550px'>\n",
    "\n",
    "http://www.brucelindbloom.com/index.html?Eqn_RGB_XYZ_Matrix.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lab\n",
    "> * L – Lightness ( Intensity ).\n",
    "> * a – color component ranging from Green to Magenta.\n",
    "> * b – color component ranging from Blue to Yellow\n",
    "\n",
    ">Lab 顏色空間與 RGB 顏色空間完全不同。在 RGB 顏色空間中，顏色信息分為三個通道，但是相同的三個通道也對亮度信息進行編碼。另一方面，在 Lab 顏色空間中，L通道與顏色信息無關，並且僅編碼亮度。其他兩個通道對顏色進行編碼。它具有以下屬性。\n",
    "\n",
    "> * 感知均勻的色彩空間，近似我們對色彩的感知方式。\n",
    "> * 與設備無關（捕獲或顯示）。\n",
    "> * 在 Adobe Photoshop 中廣泛使用。\n",
    "> * 通過複雜的轉換方程與 RGB 顏色空間相關。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hue, Saturation, Value\n",
    "import cv2\n",
    "\n",
    "# BGR\n",
    "# img = cv2.imread('./image/lenaColor.png', 1)\n",
    "img = cv2.imread('./image/fruits.png', 1)\n",
    "cv2.imshow('original', img)\n",
    "\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "cv2.imshow('HSV', hsv)\n",
    "\n",
    "hsv[:,:,1] = hsv[:,:,1] - 5                         # adjust saturation\n",
    "hsv[:,:,2] = hsv[:,:,2] - 40                        # adjust brightness\n",
    "hsv = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "cv2.imshow('BGR (after HSV adjestment)', hsv)\n",
    "\n",
    "# Hue, Lightness/Luminance, Saturation\n",
    "hls = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "cv2.imshow('HLS', hls)\n",
    "\n",
    "# Lightness, A(Green..Red), B(Blue..Yellow)\n",
    "lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "cv2.imshow('L*a*b*', lab)\n",
    "\n",
    "XYZ = cv2.cvtColor(img, cv2.COLOR_BGR2XYZ)\n",
    "cv2.imshow('XYZ', XYZ)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InRange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img=np.random.randint(0, 255, size=[5, 5], dtype=np.uint8)\n",
    "lo=100;   hi=200\n",
    "\n",
    "mask = cv2.inRange(img, lo, hi)   # 有一點像 thresh\n",
    "print(f'img=\\n{img}\\n\\n'\n",
    "      f'mask=\\n{mask}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = np.full((5,5), 9)\n",
    "# img=np.ones([5, 5], dtype=np.uint8)*9  # img.fill(9)\n",
    "\n",
    "mask =np.zeros([5, 5], dtype=np.uint8)\n",
    "mask[0:3, 0]=1; mask[2:5, 2:4]=1\n",
    "\n",
    "roi=cv2.bitwise_and(img, img, mask = mask)\n",
    "print(f'img=\\n{img}\\n\\n'\n",
    "      f'mask=\\n{mask}\\n\\n'\n",
    "      f'roi=\\n{roi}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### in HSV range\n",
    "><img src=\".\\image\\HSVinRange.png\"  style='height:250px; width:520px'>\n",
    "\n",
    "> 結合 cv2.inRange() 可以清晰看到某個顏色區域影像位於影像的什麼地方。<br>\n",
    "> 用法 cv2.inRange(img, low, high)，函式會將位於兩個區域間的值置為 255，位於區間外的值置為 0。<br>\n",
    "> 比如想要看到青色的區域處於影像中的什麼位置，青色的區域是 [78, 43, 46], [99, 255, 255]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### range of blue, green, red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "opencv=cv2.imread('./image/opencv.jpg')\n",
    "hsv = cv2.cvtColor(opencv, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "cv2.imshow('opencv', opencv)\n",
    "cv2.imshow('hsv', hsv)\n",
    "cv2.waitKey()\n",
    "#=============blue range=============\n",
    "minBlue = np.array([100,43,46])       # 從 HSV 色彩空間 110 ~ 130\n",
    "maxBlue = np.array([124,255,255])\n",
    "mask_b = cv2.inRange(hsv, minBlue, maxBlue)\n",
    "\n",
    "blue = cv2.bitwise_and(opencv, opencv, mask= mask_b)\n",
    "cv2.imshow('blue', blue)\n",
    "cv2.waitKey()\n",
    "#=============green range=============\n",
    "minGreen = np.array([35,43,46])          # 從 HSV 色彩空間 50 ~ 70\n",
    "maxGreen = np.array([77,255,255])\n",
    "mask_g = cv2.inRange(hsv, minGreen, maxGreen)\n",
    "\n",
    "green = cv2.bitwise_and(opencv, opencv, mask= mask_g)\n",
    "cv2.imshow('green', green)\n",
    "cv2.waitKey()\n",
    "#=============red range=============\n",
    "minRed = np.array([0,43,46])             # 從 HSV 色彩空間 0 ~ 30\n",
    "maxRed = np.array([10,255,255])\n",
    "mask_r = cv2.inRange(hsv, minRed, maxRed)\n",
    "\n",
    "red= cv2.bitwise_and(opencv, opencv, mask= mask_r)\n",
    "cv2.imshow('red', red)\n",
    "cv2.waitKey()\n",
    "#=============all in one============\n",
    "mask = mask_b + mask_r + mask_g\n",
    "all_inOne = cv2.bitwise_and(opencv, opencv, mask= mask) \n",
    "cv2.imshow('all_inOne', all_inOne)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "image = cv2.imread('.\\image\\mybaby.jpg')\n",
    "cv2.imshow('Original', image)\n",
    "print(image.shape)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# draw white rectangle on the center of the image\n",
    "mask = np.zeros(image.shape[:2], dtype = 'uint8')\n",
    "(cX, cY) = (image.shape[1]//2, image.shape[0]//2)\n",
    "cv2.rectangle(mask, (cX-100,cY-100), (cX+100,cY+100), 255, -1)\n",
    "cv2.imshow('Mask : rectangle', mask)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# masking image\n",
    "masked = cv2.bitwise_and(image, image, mask=mask)\n",
    "cv2.imshow('Mask rect. to Image', masked)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# draw white circle on the center of the image\n",
    "mask = np.zeros(image.shape[:2], dtype = 'uint8')\n",
    "cv2.circle(mask, (cX, cY), 100, 255, -1)\n",
    "cv2.imshow('Mask : circle', mask)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# masking image\n",
    "masked = cv2.bitwise_and(image, image, mask=mask)\n",
    "cv2.imshow('Mask circle to Image', masked)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### skin color in HSV range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img=cv2.imread('./image/lesson2.jpg')\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "minSkin = np.array([0,30,60])          # HSV 色彩空間 min\n",
    "maxSkin = np.array([25,150,255])          # HSV 色彩空間 max\n",
    "\n",
    "mask_skin = cv2.inRange(hsv, minSkin, maxSkin)\n",
    "roi = cv2.bitwise_and(img, img, mask= mask_skin)\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.imshow('ROI', roi)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BGR → HSV → BGR\n",
    "> RGB 轉換 HSV 及 HSL <br>\n",
    "> https://www.ginifab.com.tw/tools/colors/rgb_to_hsv_hsl.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img=cv2.imread('./image/barbara.bmp')\n",
    "newHSV = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "newHSV[:,:,2] = 255          # value 亮度 最亮\n",
    "\n",
    "art = cv2.cvtColor(newHSV, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "cv2.imshow('img', img)\n",
    "cv2.imshow('newHSV', newHSV)\n",
    "cv2.imshow('artBGR', art)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenCV color space conversion\n",
    "https://docs.opencv.org/master/d8/d01/group__imgproc__color__conversions.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 4. 圖片``幾何``轉換"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-1 : 線性代數複習\n",
    "> 矩陣相乘 :<br>\n",
    "> $[ 2 * 2 ] x [ 2 * 2 ] = [ 2 * 2 ]$<br>\n",
    "> $[ 2 * 3 ] x [ 3 * 2 ] = [ 2 * 2 ]$\n",
    "\n",
    "><img src=\".\\image\\matrix_product.jpg\"  style='height:100px; width:800px'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 算術運算 Add, Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Element wise Multiplication \n",
    "x = np.array([[1., 2.], [4., 5.]])\n",
    "y = np.array([[6., 23.], [-1, 7]])\n",
    "print(f'x =\\n{x}\\n\\n'\n",
    "      f'y =\\n{y}\\n\\n'\n",
    "      f'x + y =\\n{x+y}\\n\\n'\n",
    "      f'x * 2 =\\n{x*2}\\n\\n'\n",
    "      f'x * y =\\n{x*y}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### dot 矩陣和矩陣 (向量) 相乘\n",
    "$( M行, N列 ) * ( N行, L列 ) = ( M行, L列 )$<br>\n",
    "$a . b=\\begin{bmatrix}a_1 & a_2 & a_3 & a_4 & a_5\\end{bmatrix}_{(1*5)}\n",
    "\\begin{bmatrix}b_1 \\\\ b_2 \\\\ b_3 \\\\ b_4 \\\\ b_5\\end{bmatrix}_{(5*1)} = \n",
    "\\begin{bmatrix}a_1 b_1+a_2 b_2+a_3 b_3+a_4 b_4+a_5 b_5\\end{bmatrix}_{(1*1)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Element wise\n",
    "> $a x b=\\begin{bmatrix}a_1 \\\\ a_2 \\\\ a_3 \\\\ a_4 \\\\ a_5\\end{bmatrix}_{(5*1)}\n",
    "\\begin{bmatrix}b_1 \\\\ b_2 \\\\ b_3 \\\\ b_4 \\\\ b_5\\end{bmatrix}_{(5*1)} = \n",
    "\\begin{bmatrix}a_1 b_1 \\\\ a_2 b_2 \\\\ a_3 b_3 \\\\ a_4 b_4 \\\\ a_5 b_5\\end{bmatrix}_{(5*1)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1., 2.], [4., 5.]])\n",
    "y = np.array([[6., 23.], [-1, 7]])\n",
    "x, y, x.dot(y), x@y, np.dot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "x = np.array([[1., 2., 3.], [4., 5., 6.]])\n",
    "y = np.array([[6., 23.], [-1, 7], [8, 9]])\n",
    "x, y, x.dot(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transpose\n",
    "><img src=\".\\image\\matrixT.png\"  style='height:200px; width:500px'></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1., 2., 3.], [4., 5., 6.]])\n",
    "y = np.array([[6., 23.], [-1, 7], [8, 9]])\n",
    "x, x.T, y, y.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse\n",
    "$AA^{-1} = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([[6., 23.], [-1, 7]])\n",
    "np.linalg.inv(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(np.linalg.inv(y), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-2: 圖片幾何轉換介紹\n",
    "> 座標位置 row, column 轉換 (非 RGB 轉換 ) : 縮放(resize)、翻轉(flip)、平移(translate)、旋轉(Rotate)、仿射(Affine)<br>\n",
    "><img src=\".\\image\\resize.jpg\"  style='height:300px; width:700px'></img>\n",
    "><img src=\".\\image\\homogen.jpg\"  style='height:300px; width:700px'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> $ M = \\begin{pmatrix} W&A&X\\\\B&H&Y\\\\0&0&1 \\end{pmatrix}$<br>\n",
    ">>  $W, H$ : 長寬的`放大, 縮小, 翻轉`<br>\n",
    ">>  $X, Y$ : 位置的`平移`<br>\n",
    ">>  $A, B$ : 仿射"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-3: OpenCV 圖片幾何轉換\n",
    "\n",
    "> Scaling - resize() : 縮放只是調整影像大小<br>\n",
    "><img src=\".\\image\\resize01.jpg\"  style='height:300px; width:600px'></img>\n",
    "\n",
    "> ### 最後一個引數 interpolation 表示插值方式：<br>\n",
    "\n",
    ">| 插值方式       | 名稱          | 說明                                                           |\n",
    ">|:-------------:|:-------------:|:--------------------------------------------------------------:|\n",
    ">|INTER_NEAREST  | 最近鄰插值     | 邊緣不會出現緩慢的漸慢過度區域，這也導致放大的圖像容易出現鋸齒的現像 |\n",
    ">|INTER_LINEAR   | 線性插值（預設) | 線性插值是以距離為權重的一種插值方式。                            |\n",
    ">|INTER_AREA     | 區域插值       | 使用圖元區域關係進行重採樣。它可能是圖像抽取的首選方法，因為它會產生無雲紋理的結果。但是當圖像縮放時，它類似於INTER_NEAREST方法 |\n",
    ">|INTER_CUBIC    | 三次樣條插值    | ``是用某種3次方函數差值``, 可以有效避免出現鋸齒的現像, 4x4圖元鄰域的雙三次插值  |\n",
    ">|INTER_LANCZOS4 | Lanczos插值    | 是跟``傅立葉轉換``有關的三角函數的方法, 8x8圖元鄰域的Lanczos插值      |\n",
    "\n",
    "<img src=\".\\image\\resize.png\"  style='height:150px; width:700px'></img>\n",
    "https://blog.csdn.net/guyuealian/article/details/85097633"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### interpolation 插補"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = np.uint8(np.random.randint(0, 255, size=(5,5, 3)))\n",
    "height, width, _= img.shape\n",
    "\n",
    "new_dimension = (25, 25)\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.subplot(231), \n",
    "plt.title('Original Image'), plt.imshow(img)\n",
    "\n",
    "plt.subplot(232)\n",
    "resized = cv2.resize(img, new_dimension, interpolation = cv2.INTER_NEAREST)\n",
    "plt.title('INTER_NEAREST'), plt.imshow(resized)\n",
    "\n",
    "plt.subplot(233)\n",
    "resized = cv2.resize(img, new_dimension, interpolation = cv2.INTER_LINEAR)\n",
    "plt.title('INTER_LINEAR'), plt.imshow(resized)\n",
    "\n",
    "plt.subplot(234)\n",
    "resized = cv2.resize(img, new_dimension, interpolation = cv2.INTER_AREA)\n",
    "plt.title('INTER_AREA'), plt.imshow(resized)\n",
    "\n",
    "plt.subplot(235)\n",
    "resized = cv2.resize(img, new_dimension, interpolation = cv2.INTER_CUBIC)\n",
    "plt.title('INTER_CUBIC'), plt.imshow(resized)\n",
    "\n",
    "plt.subplot(236)\n",
    "resized = cv2.resize(img, new_dimension, interpolation = cv2.INTER_LANCZOS4)\n",
    "plt.title('INTER_LANCZOS4'), plt.imshow(resized)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img=cv2.imread('./image/cat.jpg')\n",
    "\n",
    "print(img.shape)\n",
    "resized_img1 = cv2.resize(img,(250, 200))   # 200 * 200 pixels\n",
    "resized_img2 = cv2.resize(img, None, fx=1.5, fy=1.5, interpolation=cv2.INTER_AREA)  # 1.5 比例放大\n",
    "\n",
    "cv2.imshow('original 414*500', img)\n",
    "cv2.imshow('resized image1 250*200', resized_img1)\n",
    "cv2.imshow('resized image2 1.5*1.5', resized_img2)\n",
    "\n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Load an color image in grayscale\n",
    "img = cv2.imread('.\\image\\mybaby.jpg',0)\n",
    "cv2.imshow('original',img)\n",
    "\n",
    "# zoom image\n",
    "h, w = img.shape[:2]\n",
    "res = cv2.resize(img, (w*2, h*2), interpolation = cv2.INTER_CUBIC)   #  w*2, h*2\n",
    "cv2.imshow('zoom image 2*2', res)\n",
    "\n",
    "# shrink image, using other parameters\n",
    "res = cv2.resize(img, None, fx=0.5, fy=0.5, interpolation = cv2.INTER_AREA) # fx=0.5, fy=0.5\n",
    "cv2.imshow('shrink image 0.5*0.5',res)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 速度比較 :\n",
    "> INTER_NEAREST（最近鄰插值) > INTER_LINEAR(線性插值) > INTER_CUBIC(三次樣條插值) > INTER_AREA  (區域插值)<br>\n",
    "> 對圖像進行縮小時，為了避免出現波紋現像，推薦採用INTER_AREA 區域插值方法。\n",
    "\n",
    "> OpenCV推薦 : <br>\n",
    "> 如果要`縮小`圖像，通常推薦使用 `INTER_AREA` 插值效果最好，而要`放大`圖像，通常使用 `INTER_CUBIC` (速度較慢，但效果最好)，或者使用 `INTER_LINEAR` (速度較快，效果還可以)。\n",
    "\n",
    ">至於最近鄰插值 INTER_NEAREST，一般不推薦使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flip\n",
    "> src ：原始影像。<br>\n",
    "> flipCode ：翻轉方向\n",
    "> * $flipCode = 0$ ，則以 X (水平) 軸為對稱軸翻轉\n",
    "> * $flipCode > 0$ ，則以 Y (垂直) 軸為對稱軸翻轉\n",
    "> * $flipCode < 0$ ，則在 X (水平) 軸、 Y (垂直) 軸方向同時翻轉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img = cv2.imread('./image/cat.jpg')\n",
    "\n",
    "flip_x = cv2.flip(img, 0)\n",
    "flip_y = cv2.flip(img, 2)\n",
    "flip_xy = cv2.flip(img, -1)\n",
    "\n",
    "cv2.imshow('original', img)\n",
    "cv2.imshow('flip x', flip_x)\n",
    "cv2.imshow('flip y', flip_y)\n",
    "cv2.imshow('flip xy', flip_xy)\n",
    "\n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### flip image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "image = cv2.imread('.\\image\\mybaby.jpg')\n",
    "cv2.imshow('Original', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "flipped = cv2.flip(image, 1)\n",
    "cv2.imshow('Flipped Horizontally left side right : 1', flipped)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "flipped = cv2.flip(image, 0)\n",
    "cv2.imshow('Flipped vertical upside down : 0', flipped)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "flipped = cv2.flip(image, -1)\n",
    "cv2.imshow('Flipped (left side right) and (upside down) : -1', flipped)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translation\n",
    "> $cv2.warpAffine(src, dst, tranformMatrix, size)$\n",
    "\n",
    "> 在影像平移中我們會用到前三個引數：\n",
    "> * src 對像，表示此操作的源（輸入圖像）。\n",
    "> * dst 表示此操作的目標（輸出圖像）的對像。\n",
    "> * 表示轉換矩陣的 tranformMatrix 對像。\n",
    "> * size−整數類型的變量，表示輸出圖像的大小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "origin = cv2.imread('./image/cat.jpg')\n",
    "\n",
    "trans_x = 80;  trans_y = 60\n",
    "h, w = origin.shape[:2]\n",
    "print(f'origin size : h:{h} / w:{w}')\n",
    "\n",
    "M = np.float32([[1, 0, trans_x], [0, 1, trans_y]])\n",
    "print('M =\\n', M)\n",
    "\n",
    "# cv2.warpAffine()函數的第三個參數是輸出圖片的大小，應該是（width, height）的形式，記住width=列數，height=行數\n",
    "trans_img = cv2.warpAffine(origin, M, (w+100, h+100))\n",
    "cv2.imshow('origin', origin)\n",
    "cv2.imshow('trans_img', trans_img)\n",
    "\n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Load an color image in grayscale\n",
    "img = cv2.imread('.\\image\\mybaby.jpg')\n",
    "\n",
    "h, w, _ = img.shape\n",
    "M = np.float32([[1,0,100], [0,1,50]])\n",
    "print('M =\\n', M)\n",
    "\n",
    "dst = cv2.warpAffine(img, M, (w+150, h+100))\n",
    "\n",
    "cv2.imshow('translation image',dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotation\n",
    "><img src=\".\\image\\rotation.jpg\"  style='height:350px; width:900px'></img>\n",
    "> 計算出一個二維旋轉的仿射矩陣\n",
    "> * center ：旋轉中心座標\n",
    "> * angle ：旋轉角度，正值意味著逆時針旋轉，座標原點為左上角\n",
    "> * scale ：縮放比例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "origin = cv2.imread('./image/cat.jpg')\n",
    "\n",
    "h, w = origin.shape[:2]\n",
    "\n",
    "M1 = cv2.getRotationMatrix2D((w/2, h/2), 45, 0.8) #表示旋轉的中心點,表示旋轉的角度,圖像縮放因子\n",
    "M2 = cv2.getRotationMatrix2D((w/2, 0), 45, 0.9)\n",
    "M3 = cv2.getRotationMatrix2D((0, h/2), -45, 0.6)\n",
    "print(f'M1 =\\n{M1}\\n\\n'\n",
    "      f'M2 =\\n{M2}\\n\\n'\n",
    "      f'M3 =\\n{M3}')\n",
    "\n",
    "rotate_img1 = cv2.warpAffine(origin, M1, (w, h))\n",
    "rotate_img2 = cv2.warpAffine(origin, M2, (w, h))\n",
    "rotate_img3 = cv2.warpAffine(origin, M3, (w, h))\n",
    "\n",
    "cv2.imshow('origin', origin)\n",
    "cv2.imshow('rotate_img1', rotate_img1)\n",
    "cv2.imshow('rotate_img2', rotate_img2)\n",
    "cv2.imshow('rotate_img3', rotate_img3)\n",
    "\n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rotate image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Load an color image in grayscale\n",
    "img = cv2.imread('.\\image\\mybaby.jpg')\n",
    "\n",
    "rows, cols, _ = img.shape\n",
    "\n",
    "# cols-1 and rows-1 are the coordinate limits\n",
    "M = cv2.getRotationMatrix2D(((cols-1)/2.0, (rows-1)/2.0), 90, 1)  # certer 是中心\n",
    "dst = cv2.warpAffine(img, M, (cols, rows))\n",
    "\n",
    "cv2.imshow('Rotate image dst', dst)\n",
    "\n",
    "img90 = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n",
    "img180 = cv2.rotate(img, cv2.ROTATE_180)\n",
    "img270 = cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "\n",
    "cv2.imshow('Rotate 90', img90)\n",
    "cv2.imshow('Rotate 180', img180)\n",
    "cv2.imshow('Rotate 270', img270)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affine Transformation\n",
    "> 在仿射變換中，原始影像中的所有平行線在輸出影像中`仍然是平行的(平行四邊形的概念`)。為了找到變換矩陣，我們需要從輸入影像中得到三個點，以及它們在輸出影像中的對應位置。然後 cv.getAffineTransform 將會建立一個 2x3 矩陣，它將被傳遞給 cv.warpAffine。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./image/cat.jpg')\n",
    "rows, cols, ch = img.shape\n",
    "\n",
    "pts1 = np.float32([[50,50], [200,50], [50,200]])\n",
    "pts2 = np.float32([[10,100], [200,50], [100,250]])\n",
    "\n",
    "M = cv2.getAffineTransform(pts1, pts2)\n",
    "print(f'M =\\n{M}')\n",
    "affine_img = cv2.warpAffine(img, M, (cols,rows))\n",
    "\n",
    "cv2.imshow('origin', img)\n",
    "cv2.imshow('affine_img', affine_img)\n",
    "\n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 透視變換\n",
    "> 要完成透視變換，你需要一個 3x3 的對映矩陣，直線會在對映之後保持筆直。要找到這個對映矩陣，你需要`四個原圖上的點`，以及它們在轉換後圖像上對應的位置。在這四個點中，`其中任意三個不能共線`。\n",
    "\n",
    "> 然後 cv2.getPerspectiveTransform 函數就能得到轉換矩陣了，再用 cv2.warpPerspective 來接收這個 3x3 的轉換矩陣。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('./image/cat.jpg')\n",
    "h, w, ch = img.shape\n",
    "\n",
    "pts1 = np.float32([[0, 0], [0, w], [h, 0], [h, w]])\n",
    "pts2 = np.float32([[0+10, 0+10], [0, w/2] ,[h/2, 0], [h/3, w/1.5]])\n",
    "\n",
    "M = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "print(f'M =\\n{M}')\n",
    "affine_img = cv2.warpPerspective(img, M, (w, h))\n",
    "\n",
    "cv2.imshow('origin', img)\n",
    "cv2.imshow('affine_img', affine_img)\n",
    "\n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 5. 濾波器\n",
    "## 5-1: 卷積運算介紹\n",
    "> 卷積一詞最開始出現在信號與系統中，是指兩個原函數產生一個新的函數的一種算子。卷積運算在運算過程可以概括為翻轉、平移再加權求和三個步驟，其中的加權求和就是乘加操作。另外，卷積運算還有一個重要的特性：空間域卷積=頻域乘積，這一點可以解釋為什麼卷積運算可以自動地提取圖像的特徵。\n",
    "\n",
    "> 在卷積神經網絡中，對數字圖像做卷積操作其實就是利用卷積核（黃底部分）在圖像（綠底部分）上滑動，將圖像上的像素灰度值與對應卷積核上的數值相乘，然後將所有相乘後的值相加作為此時的輸出值（紅底部分），並最終滑動遍歷完整副圖像的過程。\n",
    "\n",
    "><img src=\".\\image\\converlution01.jpg\"  style='height:300px; width:800px'></img>\n",
    "><img src=\".\\image\\converlution02.jpg\"  style='height:300px; width:800px'></img>\n",
    "><img src=\".\\image\\converlution01.gif\"  style='height:300px; width:800px'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 步伐 (stride) 和 填充 (padding)\n",
    "\n",
    "><img src=\".\\image\\converlution03.jpg\"  style='height:300px; width:800px'></img>\n",
    "><img src=\".\\image\\converlution04.jpg\"  style='height:300px; width:800px'></img>\n",
    "https://github.com/vdumoulin/conv_arithmetic<br>\n",
    "https://towardsdatascience.com/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-2: 卷積運算物理意義\n",
    "\n",
    "> 我們計算系統輸出時就必須考慮現在時刻的信號輸入的響應以及之前若干時刻信號輸入的響應之「殘留」影響的一個疊加效果。再拓展點，某時刻的系統響應往往不一定是由當前時刻和前一時刻這兩個響應決定的，也可能是再加上前前時刻，前前前時刻，前前前前時刻，等等\n",
    "\n",
    "><img src=\".\\image\\filter.jpg\"  style='height:400px; width:800px'></img>\n",
    "> 影像平滑模糊化是透過使用低通濾波器進行影像卷積來實現的。這對於消除雜訊很有用。實際上使用此濾波器時，它會從影像中去除高頻內容（例如，雜訊，邊緣），也會導致影像邊緣變得模糊（也有其他濾波器不會造成影像邊緣模糊）。OpenCV主要提供四種類型的平滑模糊化技術"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-3 : 平均濾波器、高斯濾波器、中值濾波器、雙邊濾波器\n",
    "> Blur & boxFilter - Average & Sum\n",
    "\n",
    "> boxFilter() 函數方框濾波所用的核為：\n",
    "><img src=\".\\image\\boxFilter.jpg\"  style='height:150px; width:900px'></img>\n",
    "> 當 $normalize = true$ 時，盒式濾波就變成了均值濾波。也就是說，均值濾波是盒式濾波歸一化（normalized）後的特殊情況。其中，歸一化就是把要處理的量都縮放到一個範圍內，比如(0,1)，以便統一處理和直觀量化。\n",
    "\n",
    "> 當 $normalize = false$ 時，為非歸一化的盒式濾波，用於計算每個圖元鄰域內的積分特性，比如密集光流演算法（dense optical flow algorithms）中用到的圖像倒數的協方差矩陣（covariance matrices of image derivatives）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### blur & boxFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread('./image/lenaNoise.png')\n",
    "result_blur = cv2.blur(img, (3, 3))\n",
    "result_box = cv2.boxFilter(img, -1, (5, 5), normalize=1)    # change 3, 3 to 5, 5 which is same as blur\n",
    "\n",
    "cv2.imshow('original', img)\n",
    "cv2.imshow('result_blur',result_blur)\n",
    "cv2.imshow('result_box', result_box)  \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blur diff. kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "o = cv2.imread('./image/lenaNoise.png')\n",
    "r5 = cv2.blur(o,(5,5))      \n",
    "r10 = cv2.blur(o,(10,10))      \n",
    "r15 = cv2.blur(o,(15,15))   \n",
    "\n",
    "cv2.imshow('original', o)\n",
    "cv2.imshow('result5', r5)\n",
    "cv2.imshow('result10', r10)\n",
    "cv2.imshow('result15', r15)\n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define other Filter \n",
    "> 2D Convolution ( Image Filtering )\n",
    "><img src=\".\\image\\filter_2d.jpg\"  style='height:200px; width:900px'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> filter2D() 函數<br>\n",
    "> $dst = cv.filter2D (src, ddepth, kernel[, dst[, anchor[, delta[, borderType]]]])$\n",
    "\n",
    "|參數       |描述                                                                |\n",
    "|:---------:|:------------------------------------------------------------------|\n",
    "|src        |原圖像                                                              |\n",
    "|dst        |目標圖像，與原圖像尺寸和通過數相同                                     |\n",
    "|ddepth\t    |目標圖像的所需深度, 當 ddepth 輸入值為-1時，靶心圖表像和原圖像深度保持一致 |\n",
    "|kernel\t    |卷積核（或相當於相關核），單通道浮點矩陣;如果要將不同的內核應用於不同的通道，請使用拆分將圖像拆分為單獨的顏色平面，然後單獨處理它們。|\n",
    "|anchor     |內核的錨點，指示內核中過濾點的相對位置;錨應位於內核中;默認值（-1，-1）表示錨位於內核中心。|\n",
    "|detal      |在將它們存儲在 dst 中之前，將可選值添加到已過濾的像素中。類似於偏置。      |\n",
    "|borderType |像素外推法，參見 BorderTypes                                           |\n",
    "\n",
    "> 其中 ddepth 表示目標圖像的所需深度，它包含有關圖像中存儲的數據類型的信息，可以是 unsigned char（CV_8U），signed char（CV_8S），unsigned short（CV_16U）等等...\n",
    "\n",
    "|Input depth (src.depth())|\tOutput depth (ddepth)|\n",
    "|:-----------:|:----------------------|\n",
    "|CV_8U\t      |-1/CV_16S/CV_32F/CV_64F|\n",
    "|CV_16U/CV_16S|-1/CV_32F/CV_64F       |\n",
    "|CV_32F\t      |-1/CV_32F/CV_64F       |\n",
    "|CV_64F       |-1/CV_64F              |\n",
    "\n",
    ">Note ：當 ddepth = -1 時，表示輸出圖像與``原圖像有相同的深度``。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boundary Padding  \n",
    "- BORDER_REPLICATE ：複製法，也就是複製最邊緣像素。\n",
    "- BORDER_REFLECT ：反射法，對感興趣的圖像中的像素在兩邊進行複製例如：fedcba | abcdefgh | hgfedcb   \n",
    "- BORDER_REFLECT_101 ：反射法，也就是以最邊緣像素為軸，對稱，gfedcb | abcdefgh | gfedcba\n",
    "- BORDER_WRAP ：外包裝法cdefgh|abcdefgh|abcdefg  \n",
    "- BORDER_CONSTANT ：常量法，常數值填充。\n",
    "><img src=\".\\image\\borderType.png\"  style='height:400px; width:500px'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### boundary padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('./image/cat.jpg', 1)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)    # 將 BGR 圖片轉為 RGB 圖片\n",
    "\n",
    "top_size = bottom_size = left_size = right_size = 50\n",
    "\n",
    "replicate = cv2.copyMakeBorder(img, top_size, bottom_size, left_size, right_size, borderType=cv2.BORDER_REPLICATE)\n",
    "reflect = cv2.copyMakeBorder(img, top_size, bottom_size, left_size, right_size,cv2.BORDER_REFLECT)\n",
    "reflect101 = cv2.copyMakeBorder(img, top_size, bottom_size, left_size, right_size, cv2.BORDER_REFLECT_101)\n",
    "wrap = cv2.copyMakeBorder(img, top_size, bottom_size, left_size, right_size, cv2.BORDER_WRAP)\n",
    "constant = cv2.copyMakeBorder(img, top_size, bottom_size, left_size, right_size,cv2.BORDER_CONSTANT, value=0)\n",
    "\n",
    "plt.figure(figsize=(14, 9))\n",
    "plt.subplot(231), plt.imshow(img), plt.title('original');\n",
    "plt.subplot(232), plt.imshow(replicate), plt.title('replicate')\n",
    "plt.subplot(233), plt.imshow(reflect), plt.title('reflect')\n",
    "plt.subplot(234), plt.imshow(reflect101), plt.title('reflect101')\n",
    "plt.subplot(235), plt.imshow(wrap), plt.title('wrap')\n",
    "plt.subplot(236), plt.imshow(constant), plt.title('constant'), plt.show()\n",
    "\n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "o = cv2.imread('./image/lenaNoise.png')\n",
    "\n",
    "# kernel = np.ones((5, 5), np.float32)/25   # how about /10\n",
    "kernel = np.full((5,5), 1/25, dtype='float32')\n",
    "print(kernel)\n",
    "r = cv2.filter2D(o, -1, kernel)  # -1 是影像深度 -1 表示與原圖相同, anchor:以中心為準, delta:offset\n",
    "# r = cv2.blur(o,(5,5))  \n",
    "cv2.imshow('original',o)\n",
    "cv2.imshow('fliter2D',r) \n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sharpen image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('.\\image\\mybaby.jpg')\n",
    "cv2.imshow('Original', img)\n",
    "\n",
    "# generating the kernels\n",
    "kernel_sharp1 = np.array([[0,-1,0],\n",
    "                          [-1,5,-1],\n",
    "                          [0,-1,0]])\n",
    "\n",
    "kernel_sharp2 = np.array([[-1,-1,-1],\n",
    "                          [-1,9,-1],\n",
    "                          [-1,-1,-1]])\n",
    "\n",
    "kernel_sharp3 = np.array([[1,1,1],\n",
    "                          [1,-7,1],\n",
    "                          [1,1,1]])\n",
    "\n",
    "kernel_sharp4 = np.array([[-1,-1,-1,-1,-1],\n",
    "                          [-1,2,2,2,-1],\n",
    "                          [-1,2,8,2,-1],\n",
    "                          [-1,2,2,2,-1],\n",
    "                          [-1,-1,-1,-1,-1]]) / 8.0\n",
    "\n",
    "# applying different kernels to the input image\n",
    "out1 = cv2.filter2D(img, -1, kernel_sharp1)\n",
    "out2 = cv2.filter2D(img, -1, kernel_sharp2)\n",
    "out3 = cv2.filter2D(img, -1, kernel_sharp3)\n",
    "out4 = cv2.filter2D(img, -1, kernel_sharp4)\n",
    "\n",
    "cv2.imshow('1. Sharpening', out1)\n",
    "cv2.imshow('2. More Sharpening', out2)\n",
    "cv2.imshow('3. Excessive Sharpening', out3)\n",
    "cv2.imshow('4. Edge Enhancement', out4)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Filter\n",
    "> 它的運作方式與 Averaging Filter 類似，但差別在於中間那個點的計算方式不同，Gaussian Filter 的作法是將給予各點不同的權值，`愈靠近中央點的權值愈高`，最後再以平均方式計算出中央點，因此，Gaussia Filter 的模糊化效果比起 Averaging 會比較明顯，但是效果卻更為自然。\n",
    "\n",
    "><img src=\".\\image\\filter_Gauss.jpg\"  style='height:250px; width:700px'></img>\n",
    "\n",
    "> $GaussianBlur(src, ksize, sigmaX, sigmaY=None, borderType=None)$\n",
    "\n",
    ">> $SigmaX = 0.3 * [(ksize.width - 1) * 0.5 -1] + 0.8$\n",
    ">> $SigmaY = 0.3 * [(ksize.width - 1) * 0.5 -1] + 0.8$<br>\n",
    "\n",
    ">> $SigmaY$ : 垂直方向的標準差預設為 0 表示與水平方向相同<br>\n",
    ">> `高斯分佈(也叫常態分佈)` 的特點為 ,標準差越大, 分佈越分散, 標準差越小, 分佈越集中.\n",
    "\n",
    "><img src=\".\\image\\Gauss.jpg\"  style='height:300px; width:500px'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## example\n",
    "> Gaussian kernel of size = 3\n",
    ">> $ Gx = \\frac{1}{16}\\begin{pmatrix}1&2&1\\\\2&4&2\\\\1&2&1\\end{pmatrix}$\n",
    "\n",
    "> Gaussian kernel of size = 5\n",
    ">> $ Gx = \\frac{1}{159}\\begin{pmatrix}2&4&5&4&2\\\\4&9&12&9&4\\\\5&12&15&12&5\\\\4&9&12&9&4\\\\2&4&5&4&2\\end{pmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sigma diff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "o = cv2.imread('image/lenaNoise.png')\n",
    "sigma0 = cv2.GaussianBlur(o, (5,5), 0, 0)   #(5, 5)是高斯矩陣的長與寬，標準差取 0 時 OpenCV 會根據高斯矩陣的尺寸自己計算\n",
    "sigma10 = cv2.GaussianBlur(o, (5,5), 10, 0) #(5, 5)是高斯矩陣的長與寬 ，標準差取 10 時 OpenCV 會根據高斯矩陣的尺寸自己計算\n",
    "\n",
    "cv2.imshow('original', o)\n",
    "cv2.imshow('sigma0', sigma0)\n",
    "cv2.imshow('sigma10', sigma10)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GaussianBlur kernal diff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "image = cv2.imread('./image/mybaby.jpg')\n",
    "cv2.imshow('Original', image)\n",
    "\n",
    "image = cv2.resize(image,(500, 280))\n",
    "\n",
    "# stack output images together\n",
    "blurred = np.hstack([\n",
    "    cv2.GaussianBlur(image, (3, 3), 0),   # kernal size 越大, sigma 愈大, 圖像愈模糊 \n",
    "    cv2.GaussianBlur(image, (5, 5), 0),\n",
    "    cv2.GaussianBlur(image, (7, 7), 0)])\n",
    "\n",
    "cv2.imshow('Gaussian 3*3, 5*5, 7*7', blurred)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median Filter 中位數\n",
    "> 計算內核窗口下所有像素的中位數，並將中心像素替換為該中位數而``不是平均值``<br>\n",
    "><img src=\".\\image\\filter_median.png\"  style='height:250px; width:500px'></img>\n",
    "\n",
    "> Average vs. Median<br>\n",
    "><img src=\".\\image\\AvgMedian.png\"  style='height:200px; width:500px'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### blur vs. medianBlur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "o=cv2.imread('image/lenaNoise.png')\n",
    "\n",
    "blur = cv2.blur(o, (3,3))\n",
    "med_blur = cv2.medianBlur(o, 3)\n",
    "\n",
    "cv2.imshow('original', o)\n",
    "cv2.imshow('blur', blur)\n",
    "cv2.imshow('median_blur', med_blur)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### medianBlur : diff kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "image = cv2.imread('./image/mybaby.jpg')\n",
    "\n",
    "cv2.imshow('Original', image)\n",
    "image = cv2.resize(image,(500, 280))\n",
    "\n",
    "# stack output images together\n",
    "blurred = np.hstack([\n",
    "    cv2.medianBlur(image, 3),\n",
    "    cv2.medianBlur(image, 5),\n",
    "    cv2.medianBlur(image, 7)])\n",
    "\n",
    "cv2.imshow('MedianBlue 3, 5, 7', blurred)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bilateral Filter 雙邊濾波器<br>\n",
    ">雙邊濾波能在保持邊界清晰的情況下有效的去除噪音。但是這種操作與其他濾波器相比會`比較慢`, 我們知道高斯濾波器是求中心點鄰近區域畫素的高斯加權平均值。這種`高斯濾波器只考慮畫素之間的空間關係`，而`不會考慮畫素值之間的關係`（畫素的相似度）。所以這種方法不會考慮一個畫素是否位於邊界。因此邊界也會被模糊掉。\n",
    "\n",
    ">雙邊濾波在同時使用`空間高斯權重`和`灰度值相似性高斯權重`。空間高斯函式確保只有鄰近區域的畫素對中心點有影響，灰度值相似性高斯函式確保只有`與中心畫素灰度值相近的才會被用來做模糊運算`。所以這種方法會確保邊界不會被模糊掉，因為邊界處的灰度值變化比較大.\n",
    "\n",
    ">簡單說就是, 在生成周邊畫素的權重矩陣時,如果發現旁邊的畫素值和當前的畫素值差異很大, 就只給差異很大的那個元素分配很小的權重,這樣`大的突變差異就被保留了`.<br>\n",
    "\n",
    "><img src=\".\\image\\bilater.png\"  style='height:450px; width:700px'></img>\n",
    "---\n",
    ">此種方法的好處是，它不但擁有 Median filter 的除噪效果，又能保留圖片中的不同物件的邊緣 (其它三種方式均會造成邊緣同時被模糊化）, 但缺點是，Bilateral Filter執行的效率較差，運算需要的時間較長。\n",
    "\n",
    "> cv2.bilateralFilter( src, d, σ_Color, σ_Space[, dst[, borderType]]) \n",
    "> * src ：影像矩陣\n",
    "> * d ：鄰域直徑\n",
    "> * sigmaColor ：顏色標準差，愈大代表在計算時需要考慮更多的顏色\n",
    "> * sigmaSpace ：空間標準差, 這個參數與Gaussian filter使用的相同，數值越大，代表越遠的像素有較大的權值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "o = cv2.imread('image/lenaNoise.png')\n",
    "r1 = cv2.bilateralFilter(o, 5, 100, 100)\n",
    "r2 = cv2.bilateralFilter(o, 5, 200, 200)\n",
    "\n",
    "cv2.imshow('original', o)\n",
    "cv2.imshow('bf:5_100*100', r1)\n",
    "cv2.imshow('bf:5_200*200', r2)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 以上可看出 bilateralFilter 對雜訊處裡效果不好, 對邊界處理較佳\n",
    "GaussianBlur vs. BilaterFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "o = cv2.imread('image/bilTest.bmp')\n",
    "\n",
    "g=r=cv2.GaussianBlur(o, (55, 55), 0, 0)\n",
    "b=cv2.bilateralFilter(o, 55, 100, 100)\n",
    "\n",
    "cv2.imshow('original',o)\n",
    "cv2.imshow('Gaussian',g)\n",
    "cv2.imshow('bilateral',b)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bilateralFilter : diff parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "image = cv2.imread('./image/mybaby.jpg')\n",
    "cv2.imshow('Original', image)\n",
    "\n",
    "image=cv2.resize(image,(500, 280))\n",
    "\n",
    "# stack output images together\n",
    "blurred = np.hstack([\n",
    "    cv2.bilateralFilter(image, 5, 20, 20),\n",
    "    cv2.bilateralFilter(image, 7, 40, 40),\n",
    "    cv2.bilateralFilter(image, 9, 60, 60)])\n",
    "\n",
    "cv2.imshow('Bilateral', blurred)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 練習 5-1\n",
    "> * 將 lenaColor.png 彩色讀入\n",
    "> * 依序濾波 (原圖 > 平均濾波 > 高斯濾波 > 中值濾波)\n",
    ">> * 平均濾波器(3*3)\n",
    ">> * 高斯濾波器(5*5)、\n",
    ">> * 中值濾波器(5*5)、\n",
    "> * 分別 show 出 : 原圖, 和三個濾波後的圖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# -------------------------\n",
    "\n",
    "\n",
    "# ----- your codes ---------\n",
    "\n",
    "# ---------------------------\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 6. 設定值處理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-1 : 什麼是 Threshold 二值化處理\n",
    "### Thresh `門檻, 閾`\n",
    "> threshold 是`門檻值`的意思，OpenCV 提供的 threshold 工具包裡面有影像門檻值的功能，當畫素值高於門檻值時，我們給這個畫素賦予一個新值（可能是白色），否則我們給它賦予另一種顏色（也許是黑色）。這個函式就是 cv2.threshold()\n",
    "\n",
    "> 圖像的二值化就是將圖像上的圖元點的`灰度值`設置為 0 或 255，這樣將使整個圖像呈現出明顯的黑白效果。在數位影像處理中，二值圖像佔有非常重要的地位，圖像的二值化使圖像中資料量大為減少，從而能凸顯出`目標的輪廓`。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> $ret, dst = cv2.threshold(src, thresh, maxval, type)$\n",
    "> * ret = thresh\n",
    "> * dst : 輸出圖 \n",
    "> * src : 輸入圖，只能輸入單通道影像，通常來說為灰度圖\n",
    "> * thresh ：閾, 門檻值\n",
    "> * maxval ：當畫素值超過了門檻值（或者小於門檻值，根據type來決定），所賦予的值\n",
    "> * type :\n",
    "\n",
    "|語法 type        |值 |說明                                                         |\n",
    "|-----------------|--|-------------------------------------------------------------|\n",
    "|THRESH_BINARY    |0 |即二值化，將大於門檻值的灰度值設為最大灰度值，小於門檻值的值設為0  |\n",
    "|THRESH_BINARY_INV|1 |將大於門檻值的灰度值設為0，其他值設為最大灰度值                  |\n",
    "|THRESH_TRUNC     |2 |將大於門檻值的灰度值設為門檻值，小於門檻值的值保持不變。(灰黑)    |\n",
    "|THRESH_TOZERO    |3 |將小於門檻值的灰度值設為0，大於門檻值的值保持不變。(黑灰白對比)   |\n",
    "|THRESH_TOZERO_INV|4 |將大於門檻值的灰度值設為0，小於門檻值的值保持不變。(黑灰強烈)     |\n",
    "\n",
    "<img src=\".\\image\\thresh4.jpg\"  style='height:350px; width:800px'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img=np.random.randint(100, 150, size=[5, 5], dtype=np.uint8)\n",
    "print(f'img : \\n{img}\\n')\n",
    "\n",
    "t1, thd = cv2.threshold(img, 125, 255, cv2.THRESH_BINARY)   # try 125\n",
    "print(f'thd :\\n{thd}\\n\\n'\n",
    "      f't1 : {t1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.resize(cv2.imread('./image/thresh.jpg', 0),(300,200))\n",
    "# img = cv2.resize(cv2.imread('./image/lenaColor.png', 0),(400, 300))\n",
    "\n",
    "ret, thresh1 = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)  # 1=255, 0=0\n",
    "ret, thresh2 = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "ret, thresh3 = cv2.threshold(img, 127, 255, cv2.THRESH_TRUNC)   # 1=127 Thresh, 0=value\n",
    "ret, thresh4 = cv2.threshold(img, 127, 255, cv2.THRESH_TOZERO)  # 1=value,  0=0\n",
    "ret, thresh5 = cv2.threshold(img, 127, 255, cv2.THRESH_TOZERO_INV)\n",
    "\n",
    "titles = ['Original Image', 'BINARY', 'BINARY_INV', 'TRUNC', 'TOZERO', 'TOZERO_INV']\n",
    "images = [img, thresh1, thresh2, thresh3, thresh4, thresh5]\n",
    "print(f'ret : {ret}')\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i + 1),  plt.imshow(images[i], 'gray')\n",
    "    plt.setp(plt.title(titles[i]), color='w')\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-2: 自我調節設定\n",
    "### threshold adaptive ``局部`` 自我調節設定\n",
    "> 自我調整門檻,閾值二值化函數根據圖片一小塊區域的值來計算對應區域的門檻, 閾值，從而得到也許更為合適的圖片。\n",
    "> * thresh_type ： 門檻, 閾值的計算方法，包含以下2種類型：\n",
    ">> * cv2.ADAPTIVE_THRESH_MEAN_C : 鄰域`面積的平均值`\n",
    ">> * cv2.ADAPTIVE_THRESH_GAUSSIAN_C : 高斯窗口的鄰域值的`加權和`\n",
    "> * Block Size ： 圖片中分塊的大小\n",
    "> * C ：閾值計算方法中的常數項src−類的對像表示源（輸入）圖像。offset ( thresh - c )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img=np.random.randint(0, 255, size=[5, 5], dtype=np.uint8)\n",
    "\n",
    "print(f'img :\\n{img}\\n')\n",
    "\n",
    "t1, thd = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)   # try 127 → 125\n",
    "print(f'threshHold : {t1}\\n\\n'\n",
    "      f'thd :\\n{thd}\\n')\n",
    "\n",
    "Ad_thd_mean = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 3, 3)\n",
    "print(f'Ad_thd_mean :\\n{Ad_thd_mean}\\n')\n",
    "\n",
    "Ad_thd_gauss = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 3, 3)\n",
    "print(f'Ad_thd_gauss :\\n{Ad_thd_mean}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "image = cv2.imread('.\\image\\mybaby.jpg', 0)\n",
    "cv2.imshow('Original', image)\n",
    "\n",
    "ret, thresh = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)  # 1 : 255, 0 : 0\n",
    "cv2.imshow('Thresh hold 127, 255', thresh)\n",
    "\n",
    "thresh = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 3, 3)\n",
    "cv2.imshow('adaptive / Mean Thresh', thresh)\n",
    "\n",
    "thresh = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 3, 3)\n",
    "cv2.imshow('adaptive /  Gaussian Thresh', thresh)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-3 : otsu 處理\n",
    "> #### Otsu 演算法假設這副圖片由前景色和背景色組成，通過統計學方法（最大類間方差）選取一個閾值，將前景和背景盡可能分開。也就是說這還是一個全域門檻, 閾值問題。\n",
    "> ### threshold otsu : 是一種自動門檻值決定法則\n",
    "><img src=\".\\image\\otsu.png\"  style='height:250px; width:520px'>\n",
    "\n",
    "### Otsu 過程 ：\n",
    "> * 計算圖像長條圖\n",
    "> * 設定一門檻, 閾值，把長條圖強度大於門檻, 閾值的圖元分成一組，把小於閾值的圖元分成另外一組\n",
    "> * 分別計算兩組內的偏移數，``並把偏移數相加``\n",
    "> * 把 0 ~ 255 依照順序多為閾值，重複 1-3 的步驟，``直到得到最小偏移數``，其所對應的值即為結果門檻, 閾值。\n",
    "\n",
    "> https://www.twblogs.net/a/5c9b5c2dbd9eee73ef4b088d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img=np.random.randint(0, 255, size=[5, 5], dtype=np.uint8)\n",
    "print(f'img : \\n{img}\\n')\n",
    "\n",
    "th2, img2 = cv2.threshold(img, 0, 255,  cv2.THRESH_OTSU)  # type\n",
    "print(f'THRESH_OTSU th2 : {th2}\\n\\n'\n",
    "      f'img2 :\\n{img2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using cv2 module\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "\n",
    "image = cv2.imread('.\\image\\mybaby.jpg', 0)\n",
    "# image = cv2.imread('.\\image\\lenaColor.png')\n",
    "\n",
    "cv2.imshow('original', image)\n",
    "\n",
    "ret, thresh = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)  # 1 : 255, 0 : 0\n",
    "cv2.imshow('Thresh hold : 127', thresh)\n",
    "\n",
    "# Otsu threshold\n",
    "th2, img2 = cv2.threshold(image, 0, 255,  cv2.THRESH_OTSU)\n",
    "print(f\"Otsu's threshold : {th2}\")\n",
    "cv2.imshow(f'Otsu : {th2}', img2)\n",
    "plt.hist(image.ravel(), 256)   # 畫直方圖\n",
    "plt.axvline(x=th2, color='r', lw=1)\n",
    "# print(plt.ylim()[1])\n",
    "plt.text(th2+5, plt.ylim()[1]*.8, f'Otsu : {th2}', fontsize=10, color='r')\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## threshold simple ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "image = cv2.imread('.\\image\\mybaby.jpg', 0)\n",
    "blurred = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "cv2.imshow('Original', image)\n",
    "\n",
    "T, thresh = cv2.threshold(blurred, 155, 255, cv2.THRESH_BINARY)\n",
    "cv2.imshow('Threshold Binary', thresh)\n",
    "\n",
    "T, threshInv = cv2.threshold(blurred, 155, 255, cv2.THRESH_BINARY_INV)\n",
    "cv2.imshow('Threshold Binary Inv.', threshInv)\n",
    "\n",
    "cv2.imshow('bitwise_and', cv2.bitwise_and(image, image, mask=threshInv))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------ the end -------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python36864bite2f03d1e5c5849e692bb3a9357569209"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
